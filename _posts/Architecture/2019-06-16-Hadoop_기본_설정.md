---
layout: post
title: '[Hadoop] Hadoop 기본 설정'
category: Architecture
tags: [hadoop]
comments: true
---

# Environment
- CentOS 7
- Hadoop 2.7.3

## core-site.xml

~~~html
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
 <property>
  <name>fs.defaultFS</name>
   <value>hdfs://hd4.cluster.kr:8020/</value>
 </property>
 <property>
  <name>io.file.buffer.size</name>
   <value>131072</value>
 </property>
<property>
  <name>hadoop.proxyuser.hadoop.groups</name>
  <value>*</value>
</property>
<property>
  <name>hadoop.proxyuser.hadoop.hosts</name>
  <value>*</value>
</property>
<property>
  <name>hadoop.proxyuser.hive2.hosts</name>
  <value>*</value>
</property>
<property>
  <name>hadoop.proxyuser.hive2.groups</name>
  <value>*</value>
</property>
</configuration>
~~~

## hdfs-site.xml

~~~html
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
 <property>
  <name>dfs.replication</name>
  <value>1</value>
 </property>
 <property>
  <name>dfs.namenode.http-address</name>
  <value>hd4.cluster.kr:50070</value>
 </property>
 <property>
  <name>dfs.namenode.secondary.http-address</name>
  <value>hd5.cluster.kr:50090</value>
 </property>
<property>
  <name>dfs.datanode.http-address</name>
  <value>0.0.0.0:50010</value>
 </property>
 <property>
  <name>dfs.namenode.name.dir</name>
   <value>file:///data/name1,file:///data/name2</value>
 </property>
 <property>
  <name>dfs.datanode.data.dir</name>
   <value>file:///data/data</value>
 </property>
 <property>
  <name>dfs.namenode.checkpoint.dir</name>
   <value>file:///data/namesecondary</value>
 </property>
 <property>
   <name>dfs.safemode.threshold.pct</name>
   <value>0</value>
 </property>
 <property>
  <name>dfs.permissions</name>
  <value>false</value>
 </property>
</configuration>
~~~



## yar-site.xml

~~~html
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
 <property>
  <name>yarn.resourcemanager.hostname</name>
   <value>hd5.cluster.kr</value>
 </property>
 <property>
  <name>yarn.nodemanager.local-dirs</name>
   <value>/data/nm</value>
 </property>
 <property>
  <name>yarn.nodemanager.aux-services</name>
   <value>mapreduce_shuffle,spark_shuffle</value>
 </property>
 <property>
  <name>yarn.nodemanager.aux-services.spark_shuffle.class</name>
   <value>org.apache.spark.network.yarn.YarnShuffleService</value>
 </property>
 <property>
   <name>yarn.resourcemanager.scheduler.class</name>
    <value>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler</value>
 </property>
 <property>
   <name>yarn.scheduler.fair.preemption</name>
    <value>true</value>
 </property>
 <property>
   <name>yarn.application.classpath</name>
    <value>/home/a/spark/yarn/spark-2.4.0-yarn-shuffle.jar</value>
 </property>
 <property>
  <name>yarn.nodemanager.resource.cpu-vcores</name>
   <value>6</value>
 </property>
 <property>
  <name>yarn.nodemanager.pmem-check-enabled</name>
   <value>false</value>
 </property>
 <property>
  <name>yarn.nodemanager.vmem-check-enabled</name>
   <value>false</value>
 </property>
</configuration>
~~~


## mappred-site.xml

~~~html
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
 <property>
  <name>mapreduce.framework.name</name>
   <value>yarn</value>
 </property>
 <property>
  <name>mapreduce.jobhistory.address</name>
   <value>hd4.cluster.kr:10020</value>
 </property>
 <property>
  <name>mapreduce.jobhistory.webapp.address</name>
   <value>hd4.cluster.kr:19888</value>
 </property>
</configuration>
~~~

