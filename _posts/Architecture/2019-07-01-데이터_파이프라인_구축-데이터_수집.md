---
layout: post
title: 데이터 파이프라인 구축 - 데이터 수집
category: Architecture
tags: [spark]
comments: true
---

# 1. 데이터 파이프라인의 이해
- 컴퓨터 과학에서 파이프라인(영어: pipeline)은 한 데이터 처리 단계의 출력이 다음 단계의 입력으로 이어지는 형태로 연결된 구조를 가리킴

## 데이터 파이프라인 구성목적
- 각 팀의 데이터적 요구사항(Use Case) 에 대한 빠른 대응 지속적이고 에러가 없어야 한다.
- 시스템적으로 발생하는 문제에 대해서 유연한 Scability 해야 한다.
- Scale up과 Scale Down이 자유로워야 한다.
- 이벤트성 데이터 부하에도 처리가 가능해야 한다.
	✓ 마케팅팀 이벤트
	✓ 푸시 발송
	✓ 서비스 오픈
- 데이터 쌓이는 공간에 문제가 없어야 한다.
- 수집데이터에 대한 Format에 대해서 유연성 있게 처리 해주어야 한다.

## Data Pipeline Architecture

<img src="https://8eyiqq.bn.files.1drv.com/y4m4O_ImOqbVm8W-EEmbIcnqx9Rhs32wbK-7QN34YDMLHFeat0kPW8LR7l8LcesO-jJ16wW7JYsl4ahcyLSU7rIYCCFvppxy-9M00x7tO_HBtWQQSvFVsEzWOHn9O7zpCTVWuW_wIpqGVwv1OhnyVSH5OEHjadaM4IijAeunDd3NwKOmITUa9bq80ru8ePCS-gyuUijdQPh03Q0cT0OeMm8Ww?width=2746&height=1198&cropmode=none"/>


## Data Lambda Architecture

<img src="https://8eyjqq.bn.files.1drv.com/y4m0JMYZmRoNT1ch43oPhw315AI5TEukOPITkndQQsq0aHNCOzo8hEnK4S7EB2VC9giTzKTaDG2mIdZ5yXMp7yb2wmQfeXXbk-4_esM_EFH8Go9V0cLwno4iwWkk4imlJeKJ_3n-XhwFdytDt--nHBc9QI3T9qzMacXZD_wCOzb_nB8Wi-6m8sPJGOPX8Tr3g39k3piVCw7DRTDRQZw39_zfg?width=2808&height=1364&cropmode=none" />


# 2. AWS 서비스 이해
## ec2(Amazon Elastic Compute Cloud)
- 인스턴스: 가상 컴퓨팅 환경
- Amazon 머신 이미지(AMI): 서버에 필요한 운영체제와 여러 소프트웨어들이 적절히 구성된 상태로 제공되는 템플릿으로 인스턴스를 쉽게 만들 수 있습니다.
- 인스턴스 유형: 인스턴스를 위한 CPU, 메모리, 스토리지, 네트워킹 용량의 여러 가지 구성 제공
- 키 쌍을 사용해 인스턴스 로그인 정보 보호(AWS는 공용키를 저장하고 사용자는 개인 키를 안전한 장소에 보관하는 방식)
- 인스턴스 스토어 볼륨: 임시 데이터를 저장하는 스토리지 볼륨으로 인스턴스 종료 시 삭제됨
- Amazon Elastic Block Store(Amazon EBS), 즉 Amazon EBS 볼륨을 사용해 영구 스토리지 볼륨에 데이터 저장
- 인스턴스와 Amazon EBS 볼륨 등의 리소스를 다른 물리적 장소에서 액세스할 수 있는 리전 및 가용 영역
- 보안 그룹을 사용해 인스턴스에 연결할 수 있는 프로토콜, 포트, 소스 IP 범위를 지정하는 방화벽 기능
- 탄력적 IP 주소(EIP): 동적 클라우드 컴퓨팅을 위한 고정 IPv4 주소
- 태그: 사용자가 생성하여 Amazon EC2 리소스에 할당할 수 있는 메타데이터
- AWS 클라우드에스는 논리적으로 격리되어 있지만, 원하실때 마다 고객님의 네트워크와 간편히 연결할 수 있는 가상 네트워크, Virtual Private Clouds(VPC)

## S3
- 버킷 : Amazon S3에 저장된 객체에 대한 컨테이너입니다. 모든 객체는 어떤 버킷에 포함됩니다. 쉽게 이해해서 윈도우의 폴더라고 이해를 하면된다.
- 객체 : Amazon S3에 저장되는 기본 개체입니다. 객체는 객체 데이터와 메타데이터로 구성됩니다
- 키: 버킷내 객체의고유한식별자입니다.버킷내 모든 객체는 정확히 하나의 키를 갖습니다. 버킷, 키 및 버전 ID의 조합이 각 객체를 고유하게 식별하기 때문에 Amazon S3는 "버킷 + 키 + 버전"과 객체 자체 사이의 기본 데이터 맵으로 간주할 수 있습니다.

## RDS(Amazon Relational Database Service)
- 클라우드에서 관계형 데이터베이스를 더욱 간편하게 설정, 운영 및 확장할 수 있음.
- 하드웨어 프로비저닝, 데이터베이스 설정, 패치 및 백업과 같은 시간 소모적인 관리 작업을 자동화하면서 비용 효율적이고 크기 조정 가능한 용량을 제공합니다
- 지원 데이터베이스 엔진
	- Oracle
	- Mysql
	- Microsoft SQL Server
	- PostgreSQL
	- MariaDB
	- Aurora

## API Gateway
- 어떤 규모에서든 개발자가 API를 생성, 게시, 유지 관리, 모니터링 및 보호할 수 있게 해주는 AWS 서비 스
- 모바일 및 웹 애플리케이션에서 AWS 서비스에 액세스할 수 있는 일관된 RESTFul 애플리케이션 프로그 래밍 인터페이스(API)를 제공합니다.
- 사용자는 RESTful API를 생성, 구성, 호스팅하여 애플리케이션의 AWS 클라우드 액세스를 지원합니다.

## CloudWatch
- Amazon Web Services(AWS) 리소스와 AWS에서 실시간으로 실행 중인 애플리케이션을 모니터링
- 리소스 및 애플리케이션에 대해 측정할 수 있는 변수인 지표를 수집하고 추적할 수 있습니다
- 경보는 알림을 보내거나 정의한 규칙을 기준으로 모니터링하는 리소스를 자동으로 변경합니다


# 3. Kafka install on EC2
## Kafka Server 설치

### JDK 설치

~~~shell
$ java –version
$ sudo yum install -y java-1.8.0-openjdk-devel.x86_64
$ sudo /usr/sbin/alternatives --config java
$ sudo /usr/sbin/alternatives --config javac
$ sudo yum remove java-1.7.0-openjdk -y
~~~

### kafka 다운

~~~shell
# kafka 다운
$ wget http://mirror.apache-kr.org/kafka/2.3.0/kafka_2.12-2.3.0.tgz

$ tar xvf kafka_2.12-2.3.0.tgz

$ ln kafka_2.12-2.3.0 kafka
~~~

### start zookeeper

~~~shell
$ cd kafka
$ vi conf/server.properties
$ listeners=PLAINTEXT://192.1.1.1:9092

$ ./bin/zookeeper-server-start.sh config/zookeeper.properties &
~~~

### start kafka broker

~~~shell
$ ./bin/kafka-server-start.sh config/server.properties &

# kafka 서버 가동 확인
$ sudo netstat -anp | egrep "9092|2181"
~~~

### create topic

~~~shell
$ bin/kafka-topics.sh --create --bootstrap-server [server-ip]:9092 --replication-factor 1 --partitions 1 --topic twitter &
~~~

### check topic : Topic 생성확인

~~~shell
$ bin/kafka-topics.sh --list --zookeeper localhost:2181 &
~~~

### Send some message

~~~shell
$ bin/kafka-console-producer.sh --broker-list [server-ip]:9092 --topic twitter
~~~

### 터미널 하나 더 생성 후 접속

### start consumer

~~~shell
$ ./kafka/bin/kafka-console-consumer.sh --bootstrap-server [server-ip]:9092 --topic twitter --from-beginning
~~~

### [참조] change topic retention bytes

~~~shell
$ ./bin/kafka-configs.sh --zookeeper localhost:2181 --entity-type topics --entity-name movie --alter --add- config retention.bytes=100000000
~~~

## kafka Producer 설치
### JDK 설치

~~~shell
$java –version

$ sudo yum install -y java-1.8.0-openjdk-devel.x86_64 $ sudo /usr/sbin/alternatives --config java
$ sudo /usr/sbin/alternatives --config javac
$ sudo yum remove java-1.7.0-openjdk -y
~~~

### Logstash 설치

~~~shell
$ rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch
$ cd /etc/yum.repos.d/

$ sudo vi logstash.repo
~~~

~~~bash
# logstash.repo
[logstash-7.x]
name=Elastic repository for 7.x packages
baseurl=https://artifacts.elastic.co/packages/7.x/yum
gpgcheck=1
gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch
enabled=1
autorefresh=1
type=rpm-md
~~~

~~~shell
$ sudo yum install logstash

$ logstash --version

$ vi producer_test.conf
~~~

~~~bash
# producer_test.conf
input {
	twitter {
		consumer_key => "KoxofBvIwdM9xxxxx"
		consumer_secret => "kKBOnftLZ6htxvxxxx"
		oauth_token => "81761998-2Vu19ZxxFwExxxxx"
		oauth_token_secret => "0E6eh4X0eum4NU81LXIKn6xxxx"
		keywords => ["news","game","data","아이돌","부동산"]
		full_tweet => true
	}
}
output {
	stdout {
		codec => rubydebug
	}
}
~~~

~~~shell
$ logstash -f producer_test.conf
~~~


~~~shell
# producer_test.conf
input {
	{
		cotwitternsumer_key => "KoxofBvIwdMxxxx" consumer_secret => "kKBOnftLZ6htxvxxxx"
		oauth_token => "81761998-2Vu19Zxxxxx" oauth_token_secret => "0E6eh4X0eum4NU81Lxxxxx" keywords => ["news","game","data","아이돌","부동산"] full_tweet => true
	}
}
output {
	kafka {
		topic_id => "twitter"
		bootstrap_servers => "[ec2의공인ip]:9092" acks => "1"
		codec => json_lines
	}
}
~~~

~~~shell
$ logstash -f producer.conf

# Kafka 서버의 Start a consumer : [개인계정]-server ec2
$ kafka/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic twitter --from-beginning
~~~

## kafka consumer 설치

~~~shell
# Logstash 설치
$ rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch
$ cd /etc/yum.repos.d/
$ sudo vi logstash.repo
~~~

~~~bash
# logstash.repo
[logstash-7.x]
name=Elastic repository for 7.x packages
baseurl=https://artifacts.elastic.co/packages/7.x/yum
gpgcheck=1 gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch
enabled=1
autorefresh=1
type=rpm-md
~~~

~~~shell
sudo yum install logstash
~~~

~~~shell
$ vi consumer.conf
~~~

~~~bash
# consumer.conf
input {
	kafka {
		bootstrap_servers => "[kafka-server]:9092" codec => json_lines
		consumer_threads => 1
		group_id => "twitter_log_to_es"
		topics => "twitter"
	}
}
output {
	stdout {
		codec => json
	}
}
~~~

~~~shell
$ logstash –f consumer.conf
~~~
